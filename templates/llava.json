{
    "name_or_path_": "liuhaotian/llava-v1.5-7b",
    "device_": "cuda",
    "dim_": 4096,
    "n_heads_": 32,
    "n_layers_": 32,
    "model_type_": "multi-modal",
    "vision_tower_": "openai/clip-vit-large-patch14",
    "vision_tower_dim_": 1024,
    "mm_vision_select_layer_": -2,
    "mm_projector_type_": "mlp2x_gelu",
    "image_token_len_": 576,
    "dtype_": "float16",
    "attn_implementation_": "flash_attn",
    "max_seq_len_": 4096,
    "vocab_size_": 32000,
    "head_dim_": 128,
    "n_kv_heads_": 32,
    "intermediate_": 11008,
    "hidden_act_": "silu",
    "hidden_dropout_": 0.0,
    "pad_token_id_": 0,
    "rope_theta_": 10000.0,
    "partial_rotary_factor_": 1.0
}