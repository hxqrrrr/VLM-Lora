{
    "model_config": {
        "name_or_path_": "TinyLlama/TinyLlama-1.1B-Chat-v0.4",
        "device_": "cuda",
        "dtype_": "float16",
        "max_seq_len_": 2048,
        "attn_implementation_": "eager",
        "dim_": null,
        "head_dim_": null,
        "intermediate_": null,
        "n_heads_": null,
        "n_kv_heads_": null,
        "n_layers_": null,
        "hidden_act_": null,
        "hidden_dropout_": null,
        "vocab_size_": null,
        "pad_token_id_": null,
        "rope_theta_": null,
        "partial_rotary_factor_": null
    },
    "lora_config": {
        "adapter_name_": "tinyllama_lora",
        "task_name_": "casual",
        "lora_r_": 8,
        "lora_alpha_": 32,
        "lora_dropout_": 0.1,
        "use_dora_": false,
        "use_rslora_": false,
        "lora_init_": "original",
        "target_modules_": [
            "self_attn.q_proj",
            "self_attn.v_proj"
        ]
    },
    "dataset_config": {
        "dataset_name_": "DTD",
        "dataset_path_": "data/dtd",
        "dataset_type_": "image_text_pair",
        "image_size_": 224,
        "max_length_": 77
    }
}